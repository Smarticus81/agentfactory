import { action } from "./_generated/server";
import { v } from "convex/values";
import { Vercel } from "@vercel/sdk";

export const createVercelDeployment = action({
  args: {
    agentId: v.string(),
    agentConfig: v.any(),
    deploymentType: v.union(v.literal("pwa"), v.literal("web"), v.literal("api")),
    userId: v.string(),
  },
  handler: async (ctx, args) => {
    try {
      // Initialize Vercel SDK with Smarticus81 account
      const vercel = new Vercel({ 
        bearerToken: process.env.VERCEL_TOKEN! 
      });

      // Create a unique project name under Smarticus81 account
      const projectName = `bevpro-agent-${args.agentId}-${Date.now()}`;
      
      // Generate deployment files
      const files = generateDeploymentFiles(args.agentConfig, args.agentId);
      
      // For now, simulate deployment since Vercel SDK has complex requirements
      // In production, this would use the actual Vercel SDK
      const mockDeployment = {
        id: `vercel_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
        url: `https://bevpro-agent-${args.agentId}-${Date.now()}.vercel.app`,
        ready: true,
        createdAt: new Date().toISOString(),
      };
      
      const deployment = mockDeployment;

      // Generate claim link for end-user
      const claimLink = await generateClaimLink(deployment.id, args.userId);

      return {
        success: true,
        deploymentId: deployment.id,
        deploymentUrl: deployment.url,
        claimLink: claimLink,
        agentId: args.agentId,
        status: 'deployed',
        timestamp: new Date().toISOString(),
      };

    } catch (error) {
      console.error("Vercel deployment failed:", error);
      throw new Error(`Deployment failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  },
});

// Helper function to generate deployment files
function generateDeploymentFiles(agentConfig: any, agentId: string) {
  const files = [
    {
      file: '/package.json',
      data: JSON.stringify({
        name: `bevpro-agent-${agentId}`,
        version: '1.0.0',
        private: true,
        scripts: {
          dev: 'next dev',
          build: 'next build',
          start: 'next start',
        },
        dependencies: {
          next: '14.0.4',
          react: '^18',
          'react-dom': '^18',
          '@vercel/sdk': '^1.10.4',
        },
      })
    },
    {
      file: '/.env.local',
      data: `# OpenAI API Key (will be set during deployment)
OPENAI_API_KEY=${process.env.OPENAI_API_KEY || 'your_openai_api_key_here'}

# Agent Configuration
AGENT_NAME=${agentConfig.name}
AGENT_TYPE=${agentConfig.type}
AGENT_INSTRUCTIONS=${agentConfig.customInstructions || 'You are a helpful voice agent for event venues and venue bars. Respond concisely and naturally as if speaking to someone. Keep responses under 100 words.'}
`
    },
    {
      file: '/next.config.js',
      data: `/** @type {import('next').NextConfig} */
const nextConfig = {
  experimental: {
    appDir: true,
  },
}

module.exports = nextConfig`
    },
    {
      file: '/app/layout.tsx',
      data: `import type { Metadata } from 'next'

export const metadata: Metadata = {
  title: '${agentConfig.name} - Voice Agent',
  description: '${agentConfig.description || 'AI Voice Agent'}',
}

export default function RootLayout({
  children,
}: {
  children: React.ReactNode
}) {
  return (
    <html lang="en">
      <body>{children}</body>
    </html>
  )
}`
    },
    {
      file: '/app/page.tsx',
      data: generateAgentPage(agentConfig, agentId)
    },
    {
      file: '/app/api/agent-api/route.ts',
      data: generateAgentAPI(agentConfig)
    },
    {
      file: '/app/globals.css',
      data: `@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  margin: 0;
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
}`
    },
    {
      file: '/tailwind.config.js',
      data: `/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    './pages/**/*.{js,ts,jsx,tsx,mdx}',
    './components/**/*.{js,ts,jsx,tsx,mdx}',
    './app/**/*.{js,ts,jsx,tsx,mdx}',
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}`
    },
    {
      file: '/postcss.config.js',
      data: `module.exports = {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}`
    },
    {
      file: '/tsconfig.json',
      data: JSON.stringify({
        compilerOptions: {
          target: "es5",
          lib: ["dom", "dom.iterable", "es6"],
          allowJs: true,
          skipLibCheck: true,
          strict: true,
          forceConsistentCasingInFileNames: true,
          noEmit: true,
          esModuleInterop: true,
          module: "esnext",
          moduleResolution: "node",
          resolveJsonModule: true,
          isolatedModules: true,
          jsx: "preserve",
          incremental: true,
          plugins: [
            {
              name: "next"
            }
          ],
          paths: {
            "@/*": ["./*"]
          }
        },
        include: ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
        exclude: ["node_modules"]
      })
    }
  ];

  return files;
}

function generateAgentPage(agentConfig: any, agentId: string): string {
  // Use pre-built template if specified, otherwise use default
  const templateId = agentConfig.templateId || (agentConfig.type === 'Event Venue' ? 'venue-modern' : 'bar-premium');
  
  // Get template from pre-built templates
  const templates = {
    'venue-modern': `'use client';

import { useState, useEffect } from 'react';

export default function ModernVenueAgent() {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);

  const startVoiceAgent = () => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';

      recognition.onstart = () => {
        setIsListening(true);
        setTranscript('');
        setResponse('');
      };

      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        setTranscript(transcript);
        processVoiceCommand(transcript);
      };

      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
      };

      recognition.onend = () => {
        setIsListening(false);
      };

      recognition.start();
    } else {
      alert('Speech recognition not supported in this browser');
    }
  };

  const processVoiceCommand = async (transcript: string) => {
    try {
      setIsProcessing(true);
      const response = await fetch('/api/agent-api', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          agentId: '${agentId}',
          message: transcript,
          type: 'voice'
        })
      });

      if (response.ok) {
        const result = await response.json();
        setResponse(result.response);
        speakResponse(result.response);
      }
    } catch (error) {
      console.error('Error processing voice command:', error);
      setResponse('Sorry, I encountered an error. Please try again.');
    } finally {
      setIsProcessing(false);
    }
  };

  const speakResponse = (text: string) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 0.9;
      utterance.pitch = 1;
      speechSynthesis.speak(utterance);
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-slate-50 to-blue-50 flex items-center justify-center p-4">
      <div className="max-w-md w-full">
        {/* Header */}
        <div className="text-center mb-8">
          <div className="w-16 h-16 bg-gradient-to-br from-blue-500 to-blue-600 rounded-2xl mx-auto mb-4 flex items-center justify-center">
            <svg className="w-8 h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M19 21V5a2 2 0 00-2-2H7a2 2 0 00-2 2v16m14 0h2m-2 0h-5m-9 0H3m2 0h5M9 7h1m-1 4h1m4-4h1m-1 4h1m-5 10v-5a1 1 0 011-1h2a1 1 0 011 1v5m-4 0h4" />
            </svg>
          </div>
          <h1 className="text-2xl font-bold text-gray-800 mb-2">${agentConfig.name}</h1>
          <p className="text-gray-600 text-sm">Professional venue management with voice AI</p>
        </div>

        {/* Voice Button */}
        <div className="text-center mb-6">
          <button
            onClick={startVoiceAgent}
            disabled={isListening || isProcessing}
            className={\`w-24 h-24 rounded-full \${isListening ? 'bg-red-500 animate-pulse' : isProcessing ? 'bg-yellow-500' : 'bg-blue-500 hover:bg-blue-600'} text-white font-bold text-lg transition-all duration-300 shadow-lg disabled:opacity-50\`}
          >
            {isListening ? 'Listening...' : isProcessing ? 'Processing...' : 'Tap to Speak'}
          </button>
        </div>

        {/* Transcript */}
        {transcript && (
          <div className="bg-white rounded-xl p-4 mb-4 shadow-sm border border-gray-100">
            <h3 className="font-semibold text-gray-700 mb-2 text-sm">You said:</h3>
            <p className="text-gray-600 text-sm">{transcript}</p>
          </div>
        )}
        
        {/* Response */}
        {response && (
          <div className="bg-blue-50 rounded-xl p-4 shadow-sm border border-blue-100">
            <h3 className="font-semibold text-blue-700 mb-2 text-sm">Response:</h3>
            <p className="text-blue-600 text-sm">{response}</p>
          </div>
        )}

        {/* Quick Actions */}
        <div className="mt-6">
          <h3 className="text-sm font-semibold text-gray-700 mb-3">Quick Actions:</h3>
          <div className="grid grid-cols-2 gap-2">
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Check Availability
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              View Pricing
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Book Event
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Contact Staff
            </button>
          </div>
        </div>
      </div>
    </div>
  );
}`,
    'bar-premium': `'use client';

import { useState, useEffect } from 'react';

export default function PremiumBarAgent() {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [response, setResponse] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);

  const startVoiceAgent = () => {
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';

      recognition.onstart = () => {
        setIsListening(true);
        setTranscript('');
        setResponse('');
      };

      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        setTranscript(transcript);
        processVoiceCommand(transcript);
      };

      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        setIsListening(false);
      };

      recognition.onend = () => {
        setIsListening(false);
      };

      recognition.start();
    } else {
      alert('Speech recognition not supported in this browser');
    }
  };

  const processVoiceCommand = async (transcript: string) => {
    try {
      setIsProcessing(true);
      const response = await fetch('/api/agent-api', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          message: transcript,
          type: 'voice'
        })
      });

      if (response.ok) {
        const result = await response.json();
        setResponse(result.response);
        speakResponse(result.response);
      }
    } catch (error) {
      console.error('Error processing voice command:', error);
      setResponse('Sorry, I encountered an error. Please try again.');
    } finally {
      setIsProcessing(false);
    }
  };

  const speakResponse = (text: string) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 0.9;
      utterance.pitch = 1;
      speechSynthesis.speak(utterance);
    }
  };

  return (
    <div className="min-h-screen bg-gradient-to-br from-amber-50 to-orange-50 flex items-center justify-center p-4">
      <div className="max-w-md w-full">
        {/* Header */}
        <div className="text-center mb-8">
          <div className="w-16 h-16 bg-gradient-to-br from-amber-500 to-orange-500 rounded-2xl mx-auto mb-4 flex items-center justify-center">
            <svg className="w-8 h-8 text-white" fill="none" stroke="currentColor" viewBox="0 0 24 24">
              <path strokeLinecap="round" strokeLinejoin="round" strokeWidth={2} d="M12 8c-1.657 0-3 .895-3 2s1.343 2 3 2 3 .895 3 2-1.343 2-3 2m0-8c1.11 0 2.08.402 2.599 1M12 8V7m0 1v8m0 0v1m0-1c-1.11 0-2.08-.402-2.599-1" />
            </svg>
          </div>
          <h1 className="text-2xl font-bold text-gray-800 mb-2">${agentConfig.name}</h1>
          <p className="text-gray-600 text-sm">Sophisticated drink service with voice AI</p>
        </div>

        {/* Voice Button */}
        <div className="text-center mb-6">
          <button
            onClick={startVoiceAgent}
            disabled={isListening || isProcessing}
            className={\`w-24 h-24 rounded-full \${isListening ? 'bg-red-500 animate-pulse' : isProcessing ? 'bg-yellow-500' : 'bg-amber-500 hover:bg-amber-600'} text-white font-bold text-lg transition-all duration-300 shadow-lg disabled:opacity-50\`}
          >
            {isListening ? 'Listening...' : isProcessing ? 'Processing...' : 'Order Now'}
          </button>
        </div>

        {/* Transcript */}
        {transcript && (
          <div className="bg-white rounded-xl p-4 mb-4 shadow-sm border border-gray-100">
            <h3 className="font-semibold text-gray-700 mb-2 text-sm">Your Order:</h3>
            <p className="text-gray-600 text-sm">{transcript}</p>
          </div>
        )}
        
        {/* Response */}
        {response && (
          <div className="bg-amber-50 rounded-xl p-4 shadow-sm border border-amber-100">
            <h3 className="font-semibold text-amber-700 mb-2 text-sm">Response:</h3>
            <p className="text-amber-600 text-sm">{response}</p>
          </div>
        )}

        {/* Quick Actions */}
        <div className="mt-6">
          <h3 className="text-sm font-semibold text-gray-700 mb-3">Quick Actions:</h3>
          <div className="grid grid-cols-2 gap-2">
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Popular Drinks
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Special Offers
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Pay Bill
            </button>
            <button className="p-3 bg-white rounded-lg text-xs text-gray-600 hover:bg-gray-50 transition-colors border border-gray-100">
              Call Staff
            </button>
          </div>
        </div>
      </div>
    </div>
  );
}`
  };

  return templates[templateId as keyof typeof templates] || templates['venue-modern'];
}

function generateAgentAPI(agentConfig: any): string {
  return `import { NextRequest } from 'next/server';

export async function POST(request: NextRequest) {
  try {
    const data = await request.json();
    const { message, type } = data;

    if (!message) {
      return Response.json({ error: "Missing message" }, { status: 400 });
    }

    // Check if OpenAI API key is configured
    if (!process.env.OPENAI_API_KEY) {
      return Response.json({ error: "OpenAI API key not configured" }, { status: 500 });
    }

    // Use embedded agent configuration
    const agentName = '${agentConfig.name}';
    const customInstructions = '${agentConfig.customInstructions || 'You are a helpful voice agent for event venues and venue bars. Respond concisely and naturally as if speaking to someone. Keep responses under 100 words.'}';
    const agentType = '${agentConfig.type}';

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": \`Bearer \${process.env.OPENAI_API_KEY}\`,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        model: "gpt-4o",
        messages: [
          {
            role: "system",
            content: \`You are \${agentName}, a voice agent for \${agentType}. \${customInstructions}\`
          },
          {
            role: "user",
            content: message
          }
        ],
        max_tokens: 200,
        temperature: 0.7,
        presence_penalty: 0.1,
        frequency_penalty: 0.1,
      }),
    });

    if (!response.ok) {
      throw new Error(\`OpenAI API error: \${response.statusText}\`);
    }

    const result = await response.json();
    const responseText = result.choices[0]?.message?.content || "I'm sorry, I didn't understand that.";

    return Response.json({
      response: responseText,
      agentName: agentName,
      timestamp: new Date().toISOString(),
      model: "gpt-4o",
      usage: result.usage
    });
  } catch (error) {
    console.error("Error processing agent request:", error);
    return Response.json({ error: "Failed to process request" }, { status: 500 });
  }
}`;
}

// Generate PWA manifest optimized for iPad Mini and iPhone
function generatePWAManifest(agentConfig: any): any {
  const isVenue = agentConfig.type === 'Event Venue';
  const themeColor = isVenue ? '#3b82f6' : '#f59e0b';
  const bgColor = isVenue ? '#f8fafc' : '#fffbeb';
  
  return {
    name: `${agentConfig.name} - Voice Assistant`,
    short_name: agentConfig.name,
    description: agentConfig.description || `${agentConfig.type} voice assistant powered by AI`,
    start_url: "/",
    display: "standalone",
    background_color: bgColor,
    theme_color: themeColor,
    orientation: "portrait-primary",
    scope: "/",
    lang: "en",
    dir: "ltr",
    categories: ["business", "productivity"],
    icons: [
      {
        src: "/icons/icon-72.png",
        sizes: "72x72",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-96.png",
        sizes: "96x96",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-128.png",
        sizes: "128x128",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-144.png",
        sizes: "144x144",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-152.png",
        sizes: "152x152",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-192.png",
        sizes: "192x192",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-384.png",
        sizes: "384x384",
        type: "image/png",
        purpose: "any maskable"
      },
      {
        src: "/icons/icon-512.png",
        sizes: "512x512",
        type: "image/png",
        purpose: "any maskable"
      }
    ],
    screenshots: [
      {
        src: "/screenshots/iphone.png",
        sizes: "390x844",
        type: "image/png",
        form_factor: "narrow"
      },
      {
        src: "/screenshots/ipad.png",
        sizes: "768x1024",
        type: "image/png",
        form_factor: "wide"
      }
    ]
  };
}

// Generate claim link for end-user to transfer ownership
async function generateClaimLink(deploymentId: string, userId: string): Promise<string> {
  // This would integrate with Vercel's team transfer functionality
  // For now, return a placeholder
  return `https://vercel.com/claim/${deploymentId}?userId=${userId}`;
}
