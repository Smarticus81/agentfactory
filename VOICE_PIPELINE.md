# üé§ Voice Pipeline Deployment Guide

## Overview

This document explains how the voice pipeline works after deployment and ensures all components stay connected and functional.

## üîÑ Voice Pipeline Flow

### 1. **User Interaction**
```
User speaks ‚Üí Browser Speech Recognition ‚Üí Transcript ‚Üí API Call ‚Üí OpenAI ‚Üí Response ‚Üí Speech Synthesis
```

### 2. **Deployed Agent Architecture**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   User Device   ‚îÇ    ‚îÇ  Deployed Agent ‚îÇ    ‚îÇ   OpenAI API    ‚îÇ
‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ    ‚îÇ                 ‚îÇ
‚îÇ ‚Ä¢ Speech Input  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ /api/agent-api‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ ‚Ä¢ GPT-4o Model  ‚îÇ
‚îÇ ‚Ä¢ Speech Output ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ ‚Ä¢ Embedded Config‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ ‚Ä¢ Voice Response‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üèóÔ∏è Deployment Components

### **1. Frontend (Deployed Agent Page)**
- **Location**: `/app/page.tsx` (generated for each agent)
- **Features**:
  - Web Speech Recognition API
  - Speech Synthesis API
  - Voice button interface
  - Real-time transcript display
  - Response visualization

### **2. Backend API (Deployed Agent API)**
- **Location**: `/app/api/agent-api/route.ts` (generated for each agent)
- **Features**:
  - Embedded agent configuration
  - OpenAI API integration
  - Error handling
  - Response formatting

### **3. Agent Configuration**
- **Embedded**: Agent config is embedded in the deployed code
- **No Database Dependency**: Deployed agents are self-contained
- **Environment Variables**: Stored in `.env.local` on deployment

## üîß Technical Implementation

### **Speech Recognition**
```javascript
const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognition = new SpeechRecognition();

recognition.continuous = false;
recognition.interimResults = false;
recognition.lang = 'en-US';

recognition.onresult = (event) => {
  const transcript = event.results[0][0].transcript;
  processVoiceCommand(transcript);
};
```

### **API Communication**
```javascript
const response = await fetch('/api/agent-api', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: transcript,
    type: 'voice'
  })
});
```

### **Speech Synthesis**
```javascript
const utterance = new SpeechSynthesisUtterance(responseText);
utterance.rate = 0.9;
utterance.pitch = 1;
speechSynthesis.speak(utterance);
```

## üöÄ Deployment Process

### **1. Agent Creation**
1. User creates agent in Bevpro Studio
2. Agent configuration is saved to Convex database
3. Default instructions are applied based on agent type

### **2. Deployment Generation**
1. Pre-built template is selected based on agent type
2. Agent configuration is embedded in the template
3. Complete Next.js application is generated
4. Environment variables are included

### **3. Vercel Deployment**
1. Application is deployed to Vercel under Smarticus81 account
2. URL format: `https://bevpro-agent-{agentId}.vercel.app`
3. Environment variables are set during deployment

## üîó Connection Points

### **1. Agent Configuration**
- **Source**: Convex database during creation
- **Deployment**: Embedded in generated code
- **Runtime**: No external dependencies

### **2. OpenAI API**
- **Authentication**: Environment variable `OPENAI_API_KEY`
- **Model**: GPT-4o (best model)
- **Response**: Natural language responses

### **3. Speech APIs**
- **Recognition**: Browser Web Speech API
- **Synthesis**: Browser Speech Synthesis API
- **Compatibility**: Works on all modern browsers

## üõ°Ô∏è Error Handling

### **1. Speech Recognition Errors**
```javascript
recognition.onerror = (event) => {
  console.error('Speech recognition error:', event.error);
  // Fallback to text input or error message
};
```

### **2. API Errors**
```javascript
if (!response.ok) {
  throw new Error(`API error: ${response.statusText}`);
}
// Graceful error handling with user feedback
```

### **3. OpenAI Errors**
```javascript
if (!process.env.OPENAI_API_KEY) {
  return Response.json({ error: "OpenAI API key not configured" }, { status: 500 });
}
```

## üì± PWA Features

### **1. Offline Capability**
- Basic functionality works without internet
- Speech recognition still works
- Cached responses for common queries

### **2. Mobile Optimization**
- Touch-friendly interface
- Responsive design
- Optimized for iPad Mini and iPhone

### **3. Installation**
- Can be added to home screen
- Works like a native app
- Full-screen experience

## üîç Monitoring & Debugging

### **1. Deployment Status**
- Check Vercel dashboard for deployment status
- Monitor function logs for API calls
- Track usage and performance

### **2. Voice Pipeline Debugging**
```javascript
// Add to deployed agent for debugging
console.log('Speech recognition started');
console.log('Transcript:', transcript);
console.log('API response:', result);
console.log('Speech synthesis:', responseText);
```

### **3. Error Tracking**
- Browser console for client-side errors
- Vercel function logs for server-side errors
- OpenAI API logs for model errors

## üö® Common Issues & Solutions

### **1. Speech Recognition Not Working**
- **Cause**: Browser permissions or HTTPS requirement
- **Solution**: Ensure HTTPS and microphone permissions

### **2. API Calls Failing**
- **Cause**: Missing OpenAI API key or network issues
- **Solution**: Check environment variables and network connectivity

### **3. Agent Configuration Missing**
- **Cause**: Deployment generation error
- **Solution**: Verify agent configuration is properly embedded

### **4. Speech Synthesis Not Working**
- **Cause**: Browser compatibility or audio settings
- **Solution**: Check browser audio settings and compatibility

## üîÑ Updates & Maintenance

### **1. Agent Updates**
- Redeploy agent with new configuration
- Update embedded instructions
- Modify voice behavior

### **2. Template Updates**
- Update pre-built templates
- Add new features
- Improve UI/UX

### **3. API Updates**
- Update OpenAI model usage
- Add new capabilities
- Improve error handling

## üìä Performance Optimization

### **1. Response Time**
- Use GPT-4o for faster responses
- Optimize API calls
- Cache common responses

### **2. Speech Quality**
- Adjust speech synthesis parameters
- Optimize for different accents
- Improve recognition accuracy

### **3. Resource Usage**
- Minimize bundle size
- Optimize for mobile devices
- Reduce API calls

## üîê Security Considerations

### **1. API Key Security**
- Environment variables for sensitive data
- No hardcoded keys in deployed code
- Secure token management

### **2. User Privacy**
- No persistent storage of voice data
- Temporary transcript storage only
- Secure communication channels

### **3. Access Control**
- Deployed agents are public
- No authentication required
- Consider rate limiting for abuse prevention

## üéØ Success Metrics

### **1. Voice Pipeline Success Rate**
- Speech recognition accuracy
- API response success rate
- Speech synthesis quality

### **2. User Experience**
- Response time
- Error rate
- User satisfaction

### **3. Technical Performance**
- Deployment success rate
- Uptime and availability
- Resource usage efficiency

---

## üìû Support

For voice pipeline issues:
1. Check browser console for errors
2. Verify environment variables
3. Test speech recognition permissions
4. Monitor Vercel function logs
5. Contact support with specific error details
